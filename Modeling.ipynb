{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stepwise_selection(X, y, \n",
    "                       initial_list=[], \n",
    "                       threshold_in=0.01, \n",
    "                       threshold_out = 0.05, \n",
    "                       verbose=True):\n",
    "    \"\"\" Perform a forward-backward feature selection \n",
    "    based on p-value from statsmodels.api.OLS\n",
    "    Arguments:\n",
    "        X - pandas.DataFrame with candidate features\n",
    "        y - list-like with the target\n",
    "        initial_list - list of features to start with (column names of X)\n",
    "        threshold_in - include a feature if its p-value < threshold_in\n",
    "        threshold_out - exclude a feature if its p-value > threshold_out\n",
    "        verbose - whether to print the sequence of inclusions and exclusions\n",
    "    Returns: list of selected features \n",
    "    Always set threshold_in < threshold_out to avoid infinite looping.\n",
    "    See https://en.wikipedia.org/wiki/Stepwise_regression for the details\n",
    "    \"\"\"\n",
    "    included = list(initial_list)\n",
    "    while True:\n",
    "        changed=False\n",
    "        # forward step\n",
    "        excluded = list(set(X.columns)-set(included))\n",
    "        new_pval = pd.Series(index=excluded)\n",
    "        for new_column in excluded:\n",
    "            model = sm.OLS(y, sm.add_constant(pd.DataFrame(X[included+[new_column]]))).fit()\n",
    "            new_pval[new_column] = model.pvalues[new_column]\n",
    "        best_pval = new_pval.min()\n",
    "        if best_pval < threshold_in:\n",
    "            best_feature = new_pval.idxmin()\n",
    "            included.append(best_feature)\n",
    "            changed=True\n",
    "            if verbose:\n",
    "                print('Add  {:30} with p-value {:.6}'.format(best_feature, best_pval))\n",
    "\n",
    "        # backward step\n",
    "        model = sm.OLS(y, sm.add_constant(pd.DataFrame(X[included]))).fit()\n",
    "        # use all coefs except intercept\n",
    "        pvalues = model.pvalues.iloc[1:]\n",
    "        worst_pval = pvalues.max() # null if pvalues is empty\n",
    "        if worst_pval > threshold_out:\n",
    "            changed=True\n",
    "            worst_feature = pvalues.argmax()\n",
    "            included.remove(worst_feature)\n",
    "            if verbose:\n",
    "                print('Drop {:30} with p-value {:.6}'.format(worst_feature, worst_pval))\n",
    "        if not changed:\n",
    "            break\n",
    "    return included"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model for Transformations 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "features = pickle.load(open('data.p', 'rb'))\n",
    "target = pickle.load(open('target.p', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((21533, 75), (21533,))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check if shapes are matching\n",
    "features.shape, target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create train & test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.10, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add  zip_98004                      with p-value 0.0\n",
      "Add  bedrooms                       with p-value 0.0\n",
      "Add  waterfront                     with p-value 0.0\n",
      "Add  sqft_living                    with p-value 0.0\n",
      "Add  zip_98039                      with p-value 9.75369e-250\n",
      "Add  zip_98112                      with p-value 8.47331e-187\n",
      "Add  zip_98040                      with p-value 9.10003e-183\n",
      "Add  zip_98105                      with p-value 8.70604e-84\n",
      "Add  zip_98119                      with p-value 2.97813e-81\n",
      "Add  zip_98033                      with p-value 8.49261e-83\n",
      "Add  zip_98199                      with p-value 5.70924e-81\n",
      "Add  zip_98006                      with p-value 2.99719e-79\n",
      "Add  zip_98103                      with p-value 2.49637e-78\n",
      "Add  zip_98115                      with p-value 6.77261e-78\n",
      "Add  zip_98117                      with p-value 3.65907e-77\n",
      "Add  zip_98102                      with p-value 6.15602e-78\n",
      "Add  zip_98109                      with p-value 1.68298e-71\n",
      "Add  zip_98122                      with p-value 2.14161e-64\n",
      "Add  zip_98107                      with p-value 4.23324e-61\n",
      "Add  zip_98116                      with p-value 3.17811e-55\n",
      "Add  zip_98023                      with p-value 9.85949e-52\n",
      "Add  zip_98144                      with p-value 7.35165e-47\n",
      "Add  sqft_lot                       with p-value 1.93545e-55\n",
      "Add  zip_98092                      with p-value 1.16147e-43\n",
      "Add  zip_98042                      with p-value 4.60254e-44\n",
      "Add  zip_98038                      with p-value 1.12995e-42\n",
      "Add  zip_98001                      with p-value 4.41051e-44\n",
      "Add  zip_98136                      with p-value 6.49137e-34\n",
      "Add  zip_98177                      with p-value 8.36964e-31\n",
      "Add  zip_98052                      with p-value 3.70892e-31\n",
      "Add  zip_98005                      with p-value 6.06802e-31\n",
      "Add  zip_98008                      with p-value 2.45331e-31\n",
      "Add  zip_98126                      with p-value 7.58402e-27\n",
      "Add  zip_98029                      with p-value 1.65775e-25\n",
      "Add  zip_98075                      with p-value 6.87299e-26\n",
      "Add  zip_98074                      with p-value 1.39787e-24\n",
      "Add  zip_98034                      with p-value 4.95276e-26\n",
      "Add  zip_98118                      with p-value 1.10173e-27\n",
      "Add  zip_98053                      with p-value 1.34338e-28\n",
      "Add  zip_98125                      with p-value 2.4527e-30\n",
      "Add  zip_98007                      with p-value 5.16943e-24\n",
      "Add  zip_98133                      with p-value 6.14671e-23\n",
      "Add  zip_98027                      with p-value 1.12957e-23\n",
      "Add  reno_age                       with p-value 9.0812e-22\n",
      "Add  zip_98106                      with p-value 4.52168e-20\n",
      "Add  zip_98155                      with p-value 2.63576e-19\n",
      "Add  zip_98108                      with p-value 1.515e-10\n",
      "Add  zip_98146                      with p-value 2.18114e-11\n",
      "Add  zip_98030                      with p-value 4.54311e-09\n",
      "Add  zip_98070                      with p-value 3.05232e-08\n",
      "Add  zip_98022                      with p-value 9.5733e-09\n",
      "Add  zip_98003                      with p-value 8.53684e-09\n",
      "Add  zip_98031                      with p-value 1.89796e-09\n",
      "Add  zip_98058                      with p-value 5.65762e-08\n",
      "Add  zip_98198                      with p-value 6.69661e-06\n",
      "Add  zip_98072                      with p-value 0.000223715\n",
      "Add  zip_98032                      with p-value 0.000508576\n",
      "Add  zip_98002                      with p-value 0.000396315\n",
      "Add  zip_98019                      with p-value 0.000596622\n",
      "Add  zip_98010                      with p-value 0.00368372\n",
      "Add  zip_98188                      with p-value 0.00381701\n",
      "Add  zip_98045                      with p-value 0.00264042\n",
      "Add  zip_98055                      with p-value 0.0040929\n"
     ]
    }
   ],
   "source": [
    "#peform stepwise selection for model 1 (transformation 1)\n",
    "included = stepwise_selection(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build final model\n",
    "linreg = LinearRegression().fit(X_train[included] , y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7011474334990777"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linreg.score(X_train[included], y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model with Transformations 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get second way of transforming values and create splits\n",
    "features_2 = pickle.load(open('data_2.p', 'rb'))\n",
    "X2_train, X2_test, y_train, y_test = train_test_split(features_2, target, test_size=0.10, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check if same set of data points (with different columns created)\n",
    "a = np.array([X_train.index == X2_train.index])\n",
    "a.all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sqft_living15', 'sqft_lot', 'bathrooms', 'bedrooms', 'grade',\n",
       "       'reno_age', 'waterfront', 'zip_98001', 'zip_98002', 'zip_98003',\n",
       "       'zip_98004', 'zip_98005', 'zip_98006', 'zip_98007', 'zip_98008',\n",
       "       'zip_98010', 'zip_98011', 'zip_98014', 'zip_98019', 'zip_98022',\n",
       "       'zip_98023', 'zip_98024', 'zip_98027', 'zip_98028', 'zip_98029',\n",
       "       'zip_98030', 'zip_98031', 'zip_98032', 'zip_98033', 'zip_98034',\n",
       "       'zip_98038', 'zip_98039', 'zip_98040', 'zip_98042', 'zip_98045',\n",
       "       'zip_98052', 'zip_98053', 'zip_98055', 'zip_98056', 'zip_98058',\n",
       "       'zip_98059', 'zip_98065', 'zip_98070', 'zip_98072', 'zip_98074',\n",
       "       'zip_98075', 'zip_98077', 'zip_98092', 'zip_98102', 'zip_98103',\n",
       "       'zip_98105', 'zip_98106', 'zip_98107', 'zip_98108', 'zip_98109',\n",
       "       'zip_98112', 'zip_98115', 'zip_98116', 'zip_98117', 'zip_98118',\n",
       "       'zip_98119', 'zip_98122', 'zip_98125', 'zip_98126', 'zip_98133',\n",
       "       'zip_98136', 'zip_98144', 'zip_98146', 'zip_98148', 'zip_98155',\n",
       "       'zip_98166', 'zip_98168', 'zip_98177', 'zip_98178', 'zip_98188',\n",
       "       'zip_98198', 'zip_98199'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#double check cofrecgt columns\n",
    "X2_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add  zip_98004                      with p-value 0.0\n",
      "Add  bedrooms                       with p-value 0.0\n",
      "Add  waterfront                     with p-value 0.0\n",
      "Add  sqft_living15                  with p-value 0.0\n",
      "Add  grade                          with p-value 0.0\n",
      "Add  reno_age                       with p-value 1.11058e-304\n",
      "Add  zip_98039                      with p-value 9.61827e-253\n",
      "Add  zip_98112                      with p-value 1.11476e-124\n",
      "Add  zip_98040                      with p-value 2.21252e-129\n",
      "Add  bathrooms                      with p-value 2.66016e-89\n",
      "Drop bedrooms                       with p-value 0.115319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/learn-env/lib/python3.6/site-packages/ipykernel_launcher.py:43: FutureWarning: 'argmax' is deprecated, use 'idxmax' instead. The behavior of 'argmax'\n",
      "will be corrected to return the positional maximum in the future.\n",
      "Use 'series.values.argmax' to get the position of the maximum now.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add  zip_98023                      with p-value 6.15675e-88\n",
      "Add  zip_98033                      with p-value 8.06056e-71\n",
      "Add  zip_98092                      with p-value 1.50734e-52\n",
      "Add  zip_98042                      with p-value 4.00469e-49\n",
      "Add  zip_98003                      with p-value 2.61939e-50\n",
      "Add  zip_98105                      with p-value 1.53027e-47\n",
      "Add  zip_98119                      with p-value 2.58371e-46\n",
      "Add  zip_98199                      with p-value 3.17093e-47\n",
      "Add  zip_98115                      with p-value 1.573e-43\n",
      "Add  zip_98117                      with p-value 6.79352e-44\n",
      "Add  zip_98103                      with p-value 5.59218e-48\n",
      "Add  zip_98109                      with p-value 1.58287e-42\n",
      "Add  zip_98006                      with p-value 1.38833e-39\n",
      "Add  zip_98102                      with p-value 1.0332e-40\n",
      "Add  zip_98038                      with p-value 2.30901e-34\n",
      "Add  zip_98058                      with p-value 2.53512e-36\n",
      "Add  zip_98001                      with p-value 2.50006e-38\n",
      "Add  sqft_lot                       with p-value 9.03272e-40\n",
      "Add  zip_98144                      with p-value 2.59032e-38\n",
      "Add  zip_98107                      with p-value 2.49343e-41\n",
      "Add  zip_98116                      with p-value 8.76273e-45\n",
      "Add  zip_98122                      with p-value 3.66084e-49\n",
      "Add  zip_98031                      with p-value 5.08281e-33\n",
      "Add  zip_98030                      with p-value 1.92454e-34\n",
      "Add  zip_98136                      with p-value 2.08599e-23\n",
      "Add  zip_98022                      with p-value 1.05142e-21\n",
      "Add  zip_98198                      with p-value 3.54211e-21\n",
      "Add  zip_98126                      with p-value 2.23838e-19\n",
      "Add  zip_98177                      with p-value 6.24422e-19\n",
      "Add  zip_98118                      with p-value 7.41527e-18\n",
      "Add  zip_98008                      with p-value 5.40202e-19\n",
      "Add  zip_98125                      with p-value 1.30269e-15\n",
      "Add  bedrooms                       with p-value 7.26423e-15\n",
      "Add  zip_98070                      with p-value 1.47317e-13\n",
      "Add  zip_98005                      with p-value 8.47669e-13\n",
      "Add  zip_98052                      with p-value 7.90029e-13\n",
      "Add  zip_98053                      with p-value 4.38729e-13\n",
      "Add  zip_98034                      with p-value 3.83412e-12\n",
      "Add  zip_98032                      with p-value 4.60371e-10\n",
      "Add  zip_98106                      with p-value 1.96427e-08\n",
      "Add  zip_98133                      with p-value 9.9784e-10\n",
      "Add  zip_98029                      with p-value 6.73451e-10\n",
      "Add  zip_98007                      with p-value 4.64766e-08\n",
      "Add  zip_98075                      with p-value 9.7647e-07\n",
      "Add  zip_98146                      with p-value 1.65087e-06\n",
      "Add  zip_98155                      with p-value 5.30696e-06\n",
      "Add  zip_98027                      with p-value 1.21635e-06\n",
      "Add  zip_98074                      with p-value 1.31324e-07\n",
      "Add  zip_98108                      with p-value 2.5796e-07\n",
      "Add  zip_98056                      with p-value 0.000414679\n",
      "Add  zip_98065                      with p-value 0.000181631\n",
      "Add  zip_98024                      with p-value 0.00763598\n"
     ]
    }
   ],
   "source": [
    "#perform stepwise selection for model 2: transformations 2\n",
    "included2 = stepwise_selection(X2_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['zip_98055',\n",
       " 'zip_98188',\n",
       " 'sqft_living',\n",
       " 'zip_98002',\n",
       " 'zip_98019',\n",
       " 'zip_98010',\n",
       " 'zip_98072',\n",
       " 'zip_98045']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check that we selected different features from model 1\n",
    "list(set(included) - set(included2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build model 2 with selected features\n",
    "linreg1 = LinearRegression().fit(X2_train[included2] , y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7103143915230632"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linreg1.score(X2_train[included2] , y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like there was some improvement, but see next section for full comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction & comparison of models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.707\n",
      "0.716\n"
     ]
    }
   ],
   "source": [
    "#Get prdictions from different models\n",
    "print(round(linreg.score(X_test[included], y_test), 3))\n",
    "print(round(linreg1.score(X2_test[included2], y_test) , 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Adjusted R Squared in this second model has a .01 improvement over the first model using hte test set similar to the train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get predictions for test and train for both models to use in RMSE calculations\n",
    "y_hat_test = linreg.predict(X_test[included])\n",
    "y2_hat_test = linreg1.predict(X2_test[included2])\n",
    "\n",
    "ytrain_hat_test = linreg.predict(X_train[included])\n",
    "ytrain2_hat_test = linreg1.predict(X2_train[included2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First model train RMSE: 200767\n",
      "Second model train RMSE: 197664\n",
      "First model root RMSE: 192274\n",
      "Second model root RMSE: 189197\n",
      "-8493\n",
      "-8467\n"
     ]
    }
   ],
   "source": [
    "#get rmse values & print diff\n",
    "linereg_rmse_train = np.sqrt(mean_squared_error(y_train, ytrain_hat_test))\n",
    "linereg2_rmse_train = np.sqrt(mean_squared_error(y_train, ytrain2_hat_test))\n",
    "\n",
    "linereg_rmse = np.sqrt(mean_squared_error(y_test, y_hat_test))\n",
    "linereg2_rmse = np.sqrt(mean_squared_error(y_test, y2_hat_test))\n",
    "\n",
    "print('First model train RMSE:', int(linereg_rmse_train))\n",
    "print('Second model train RMSE:', int(linereg2_rmse_train))\n",
    "\n",
    "print('First model root RMSE:', int(linereg_rmse))\n",
    "print('Second model root RMSE:', int(linereg2_rmse))\n",
    "print(int(linereg_rmse - linereg_rmse_train ))\n",
    "print(int(linereg2_rmse - linereg2_rmse_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second model is best by several different measures. Scores on the train and test said is better by 0.1. The RMSE is better by about 3,000 dollars. Both models have a similar difference in train & test RMSE so neither one is better in terms of over or underfitting.  Second model is best. Going forward, I use the second set of transformaiton to add date and lat/long features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling with transformations 2 & date info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data with second transformations & date info\n",
    "features_date = pickle.load(open('data_2_date.p', 'rb'))\n",
    "XD_train, XD_test, y_train, y_test = train_test_split(features_date, target, test_size=0.10, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check if same set of data points (with different columns created)\n",
    "a = np.array([XD_train.index == X2_train.index])\n",
    "a.all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add  zip_98004                      with p-value 0.0\n",
      "Add  bedrooms                       with p-value 0.0\n",
      "Add  waterfront                     with p-value 0.0\n",
      "Add  sqft_living15                  with p-value 0.0\n",
      "Add  grade                          with p-value 0.0\n",
      "Add  reno_age                       with p-value 1.11058e-304\n",
      "Add  zip_98039                      with p-value 9.61827e-253\n",
      "Add  zip_98112                      with p-value 1.11476e-124\n",
      "Add  zip_98040                      with p-value 2.21252e-129\n",
      "Add  bathrooms                      with p-value 2.66016e-89\n",
      "Drop bedrooms                       with p-value 0.115319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/learn-env/lib/python3.6/site-packages/ipykernel_launcher.py:43: FutureWarning: 'argmax' is deprecated, use 'idxmax' instead. The behavior of 'argmax'\n",
      "will be corrected to return the positional maximum in the future.\n",
      "Use 'series.values.argmax' to get the position of the maximum now.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add  zip_98023                      with p-value 6.15675e-88\n",
      "Add  zip_98033                      with p-value 8.06056e-71\n",
      "Add  zip_98092                      with p-value 1.50734e-52\n",
      "Add  zip_98042                      with p-value 4.00469e-49\n",
      "Add  zip_98003                      with p-value 2.61939e-50\n",
      "Add  zip_98105                      with p-value 1.53027e-47\n",
      "Add  zip_98119                      with p-value 2.58371e-46\n",
      "Add  zip_98199                      with p-value 3.17093e-47\n",
      "Add  zip_98115                      with p-value 1.573e-43\n",
      "Add  zip_98117                      with p-value 6.79352e-44\n",
      "Add  zip_98103                      with p-value 5.59218e-48\n",
      "Add  zip_98109                      with p-value 1.58287e-42\n",
      "Add  zip_98006                      with p-value 1.38833e-39\n",
      "Add  zip_98102                      with p-value 1.0332e-40\n",
      "Add  zip_98038                      with p-value 2.30901e-34\n",
      "Add  zip_98058                      with p-value 2.53512e-36\n",
      "Add  zip_98001                      with p-value 2.50006e-38\n",
      "Add  sqft_lot                       with p-value 9.03272e-40\n",
      "Add  zip_98144                      with p-value 2.59032e-38\n",
      "Add  zip_98107                      with p-value 2.49343e-41\n",
      "Add  zip_98116                      with p-value 8.76273e-45\n",
      "Add  zip_98122                      with p-value 3.66084e-49\n",
      "Add  zip_98031                      with p-value 5.08281e-33\n",
      "Add  zip_98030                      with p-value 1.92454e-34\n",
      "Add  zip_98136                      with p-value 2.08599e-23\n",
      "Add  zip_98022                      with p-value 1.05142e-21\n",
      "Add  zip_98198                      with p-value 3.54211e-21\n",
      "Add  zip_98126                      with p-value 2.23838e-19\n",
      "Add  zip_98177                      with p-value 6.24422e-19\n",
      "Add  zip_98118                      with p-value 7.41527e-18\n",
      "Add  zip_98008                      with p-value 5.40202e-19\n",
      "Add  day_since_min                  with p-value 1.31146e-16\n",
      "Add  zip_98125                      with p-value 7.6986e-16\n",
      "Add  bedrooms                       with p-value 8.478e-15\n",
      "Add  zip_98070                      with p-value 2.30318e-13\n",
      "Add  zip_98005                      with p-value 9.23495e-13\n",
      "Add  zip_98052                      with p-value 2.80386e-13\n",
      "Add  zip_98053                      with p-value 4.11849e-13\n",
      "Add  zip_98034                      with p-value 3.12053e-12\n",
      "Add  zip_98032                      with p-value 3.88669e-10\n",
      "Add  zip_98133                      with p-value 2.3984e-08\n",
      "Add  zip_98106                      with p-value 1.63252e-09\n",
      "Add  zip_98029                      with p-value 4.2609e-10\n",
      "Add  zip_98007                      with p-value 2.91142e-08\n",
      "Add  zip_98075                      with p-value 1.05478e-06\n",
      "Add  zip_98146                      with p-value 2.94547e-06\n",
      "Add  zip_98027                      with p-value 3.89912e-06\n",
      "Add  zip_98074                      with p-value 6.09122e-07\n",
      "Add  zip_98155                      with p-value 1.21829e-07\n",
      "Add  zip_98108                      with p-value 1.36297e-07\n",
      "Add  zip_98056                      with p-value 0.000453558\n",
      "Add  zip_98065                      with p-value 0.00021474\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['zip_98004',\n",
       " 'waterfront',\n",
       " 'sqft_living15',\n",
       " 'grade',\n",
       " 'reno_age',\n",
       " 'zip_98039',\n",
       " 'zip_98112',\n",
       " 'zip_98040',\n",
       " 'bathrooms',\n",
       " 'zip_98023',\n",
       " 'zip_98033',\n",
       " 'zip_98092',\n",
       " 'zip_98042',\n",
       " 'zip_98003',\n",
       " 'zip_98105',\n",
       " 'zip_98119',\n",
       " 'zip_98199',\n",
       " 'zip_98115',\n",
       " 'zip_98117',\n",
       " 'zip_98103',\n",
       " 'zip_98109',\n",
       " 'zip_98006',\n",
       " 'zip_98102',\n",
       " 'zip_98038',\n",
       " 'zip_98058',\n",
       " 'zip_98001',\n",
       " 'sqft_lot',\n",
       " 'zip_98144',\n",
       " 'zip_98107',\n",
       " 'zip_98116',\n",
       " 'zip_98122',\n",
       " 'zip_98031',\n",
       " 'zip_98030',\n",
       " 'zip_98136',\n",
       " 'zip_98022',\n",
       " 'zip_98198',\n",
       " 'zip_98126',\n",
       " 'zip_98177',\n",
       " 'zip_98118',\n",
       " 'zip_98008',\n",
       " 'day_since_min',\n",
       " 'zip_98125',\n",
       " 'bedrooms',\n",
       " 'zip_98070',\n",
       " 'zip_98005',\n",
       " 'zip_98052',\n",
       " 'zip_98053',\n",
       " 'zip_98034',\n",
       " 'zip_98032',\n",
       " 'zip_98133',\n",
       " 'zip_98106',\n",
       " 'zip_98029',\n",
       " 'zip_98007',\n",
       " 'zip_98075',\n",
       " 'zip_98146',\n",
       " 'zip_98027',\n",
       " 'zip_98074',\n",
       " 'zip_98155',\n",
       " 'zip_98108',\n",
       " 'zip_98056',\n",
       " 'zip_98065']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#perform stepwise selection\n",
    "included_d = stepwise_selection(XD_train, y_train)\n",
    "included_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7113005967470172"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#build final model and get score\n",
    "linreg_d = LinearRegression().fit(XD_train[included_d] , y_train)\n",
    "linreg_d.score(XD_train[included_d] , y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7189371247594474\n",
      "First model RMSE: 192274\n",
      "Second Model RMSE: 189197\n",
      "Third Model RMSE: 188268\n"
     ]
    }
   ],
   "source": [
    "#Get prdictions from different models\n",
    "print(linreg_d.score(XD_test[included_d], y_test))\n",
    "yD_hat_test = linreg_d.predict(XD_test[included_d])\n",
    "\n",
    "linreg_d_rmse = np.sqrt(mean_squared_error(y_test, yD_hat_test))\n",
    "print('First model RMSE:', int(linereg_rmse))\n",
    "print('Second Model RMSE:', int(linereg2_rmse))\n",
    "print('Third Model RMSE:', int(linreg_d_rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This third model does better than the first two. Both in the train (0.711) and test scores (0.718) compared to the second model which had train 0.710 and 0.716 on the test data. Similarly, the RMSE is about 1.8k better error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sqft_living15', 'sqft_lot', 'bathrooms', 'bedrooms', 'grade',\n",
       "       'reno_age', 'waterfront', 'zip_98001', 'zip_98002', 'zip_98003',\n",
       "       'zip_98004', 'zip_98005', 'zip_98006', 'zip_98007', 'zip_98008',\n",
       "       'zip_98010', 'zip_98011', 'zip_98014', 'zip_98019', 'zip_98022',\n",
       "       'zip_98023', 'zip_98024', 'zip_98027', 'zip_98028', 'zip_98029',\n",
       "       'zip_98030', 'zip_98031', 'zip_98032', 'zip_98033', 'zip_98034',\n",
       "       'zip_98038', 'zip_98039', 'zip_98040', 'zip_98042', 'zip_98045',\n",
       "       'zip_98052', 'zip_98053', 'zip_98055', 'zip_98056', 'zip_98058',\n",
       "       'zip_98059', 'zip_98065', 'zip_98070', 'zip_98072', 'zip_98074',\n",
       "       'zip_98075', 'zip_98077', 'zip_98092', 'zip_98102', 'zip_98103',\n",
       "       'zip_98105', 'zip_98106', 'zip_98107', 'zip_98108', 'zip_98109',\n",
       "       'zip_98112', 'zip_98115', 'zip_98116', 'zip_98117', 'zip_98118',\n",
       "       'zip_98119', 'zip_98122', 'zip_98125', 'zip_98126', 'zip_98133',\n",
       "       'zip_98136', 'zip_98144', 'zip_98146', 'zip_98148', 'zip_98155',\n",
       "       'zip_98166', 'zip_98168', 'zip_98177', 'zip_98178', 'zip_98188',\n",
       "       'zip_98198', 'zip_98199', 'year_month', 'day_since_min'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#inspect columns chosen for this model\n",
    "XD_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model with Transformations 2, date and lat/long numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load and select data\n",
    "features_date_latlong = pickle.load(open('data_2_date_latlong.p', 'rb'))\n",
    "XDL_train, XDL_test, y_train, y_test = train_test_split(features_date_latlong, target, test_size=0.10, random_state=42)\n",
    "\n",
    "#check if same set of data points (with different columns created)\n",
    "a = np.array([XDL_train.index == X_train.index])\n",
    "a.all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add  zip_98004                      with p-value 0.0\n",
      "Add  bedrooms                       with p-value 0.0\n",
      "Add  waterfront                     with p-value 0.0\n",
      "Add  lat                            with p-value 0.0\n",
      "Add  sqft_living15                  with p-value 0.0\n",
      "Add  grade                          with p-value 0.0\n",
      "Add  zip_98039                      with p-value 7.55554e-271\n",
      "Add  reno_age                       with p-value 5.08135e-197\n",
      "Add  zip_98040                      with p-value 5.25154e-142\n",
      "Add  zip_98112                      with p-value 6.4036e-138\n",
      "Add  bathrooms                      with p-value 2.48206e-90\n",
      "Add  zip_98033                      with p-value 1.06931e-39\n",
      "Add  zip_98119                      with p-value 1.84216e-40\n",
      "Add  zip_98006                      with p-value 8.62583e-40\n",
      "Add  zip_98105                      with p-value 4.31884e-42\n",
      "Add  zip_98199                      with p-value 8.39708e-42\n",
      "Add  zip_98109                      with p-value 5.86161e-36\n",
      "Add  zip_98102                      with p-value 1.9426e-32\n",
      "Add  zip_98028                      with p-value 3.31822e-29\n",
      "Add  zip_98155                      with p-value 6.87763e-30\n",
      "Add  zip_98133                      with p-value 4.81327e-30\n",
      "Add  sqft_lot                       with p-value 1.22683e-29\n",
      "Add  long                           with p-value 1.67933e-54\n",
      "Add  zip_98011                      with p-value 7.32148e-33\n",
      "Add  zip_98072                      with p-value 5.2425e-35\n",
      "Add  zip_98077                      with p-value 1.85551e-30\n",
      "Add  zip_98019                      with p-value 1.48869e-31\n",
      "Add  zip_98034                      with p-value 2.19264e-35\n",
      "Add  zip_98125                      with p-value 3.17636e-30\n",
      "Add  zip_98022                      with p-value 1.1224e-33\n",
      "Add  zip_98144                      with p-value 2.9846e-20\n",
      "Add  zip_98177                      with p-value 3.14613e-18\n",
      "Add  zip_98052                      with p-value 4.969e-21\n",
      "Add  zip_98002                      with p-value 4.65569e-18\n",
      "Add  day_since_min                  with p-value 1.09699e-16\n",
      "Add  zip_98122                      with p-value 2.2983e-14\n",
      "Add  zip_98116                      with p-value 9.07485e-16\n",
      "Add  zip_98014                      with p-value 2.65923e-14\n",
      "Add  zip_98074                      with p-value 1.40975e-13\n",
      "Add  zip_98053                      with p-value 1.18976e-16\n",
      "Add  zip_98136                      with p-value 9.52362e-12\n",
      "Add  zip_98010                      with p-value 3.89532e-11\n",
      "Add  zip_98058                      with p-value 4.45736e-10\n",
      "Add  zip_98070                      with p-value 2.5611e-09\n",
      "Add  zip_98126                      with p-value 7.36266e-06\n",
      "Add  zip_98103                      with p-value 1.04424e-05\n",
      "Add  zip_98118                      with p-value 4.02482e-06\n",
      "Add  zip_98107                      with p-value 7.1186e-05\n",
      "Add  zip_98115                      with p-value 1.18261e-06\n",
      "Add  zip_98117                      with p-value 3.84634e-10\n",
      "Add  zip_98031                      with p-value 0.000108099\n",
      "Add  zip_98008                      with p-value 0.00114162\n",
      "Add  zip_98029                      with p-value 0.000389062\n",
      "Add  zip_98027                      with p-value 0.000905105\n",
      "Add  zip_98005                      with p-value 0.000538668\n",
      "Add  zip_98106                      with p-value 0.00100552\n",
      "Add  zip_98146                      with p-value 0.000125322\n",
      "Drop zip_98177                      with p-value 0.245455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/learn-env/lib/python3.6/site-packages/ipykernel_launcher.py:43: FutureWarning: 'argmax' is deprecated, use 'idxmax' instead. The behavior of 'argmax'\n",
      "will be corrected to return the positional maximum in the future.\n",
      "Use 'series.values.argmax' to get the position of the maximum now.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['zip_98004',\n",
       " 'bedrooms',\n",
       " 'waterfront',\n",
       " 'lat',\n",
       " 'sqft_living15',\n",
       " 'grade',\n",
       " 'zip_98039',\n",
       " 'reno_age',\n",
       " 'zip_98040',\n",
       " 'zip_98112',\n",
       " 'bathrooms',\n",
       " 'zip_98033',\n",
       " 'zip_98119',\n",
       " 'zip_98006',\n",
       " 'zip_98105',\n",
       " 'zip_98199',\n",
       " 'zip_98109',\n",
       " 'zip_98102',\n",
       " 'zip_98028',\n",
       " 'zip_98155',\n",
       " 'zip_98133',\n",
       " 'sqft_lot',\n",
       " 'long',\n",
       " 'zip_98011',\n",
       " 'zip_98072',\n",
       " 'zip_98077',\n",
       " 'zip_98019',\n",
       " 'zip_98034',\n",
       " 'zip_98125',\n",
       " 'zip_98022',\n",
       " 'zip_98144',\n",
       " 'zip_98052',\n",
       " 'zip_98002',\n",
       " 'day_since_min',\n",
       " 'zip_98122',\n",
       " 'zip_98116',\n",
       " 'zip_98014',\n",
       " 'zip_98074',\n",
       " 'zip_98053',\n",
       " 'zip_98136',\n",
       " 'zip_98010',\n",
       " 'zip_98058',\n",
       " 'zip_98070',\n",
       " 'zip_98126',\n",
       " 'zip_98103',\n",
       " 'zip_98118',\n",
       " 'zip_98107',\n",
       " 'zip_98115',\n",
       " 'zip_98117',\n",
       " 'zip_98031',\n",
       " 'zip_98008',\n",
       " 'zip_98029',\n",
       " 'zip_98027',\n",
       " 'zip_98005',\n",
       " 'zip_98106',\n",
       " 'zip_98146']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# perform stepwise selection\n",
    "included_dl = stepwise_selection(XDL_train, y_train)\n",
    "included_dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7105326931771181"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#build final model and get scores\n",
    "linreg_dl = LinearRegression().fit(XDL_train[included_dl] , y_train)\n",
    "linreg_dl.score(XDL_train[included_dl] , y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data Scores\n",
      "0.7011474334990777\n",
      "0.7103143915230632\n",
      "0.7113005967470172\n",
      "0.7105326931771181\n",
      "-------\n",
      "Test Data Scores\n",
      "0.7068502240248487\n",
      "0.7161579090671364\n",
      "0.7189371247594474\n",
      "0.7176605239320484\n",
      "-------\n",
      "Train RMSE-------\n",
      "First model train rmse: 200767.0\n",
      "Second model train rmse: 197664.0\n",
      "Model with dates train rmse: 197328.0\n",
      "Model with dates & train zone rmse: 197590.0\n",
      "Test RMSE-------\n",
      "First model rmse: 192274.0\n",
      "Second Model rmse: 189197.0\n",
      "Model with dates rmse: 188269.0\n",
      "Model with dates & zone rmse: 188696.0\n"
     ]
    }
   ],
   "source": [
    "#Get score of train data\n",
    "print('Train Data Scores')\n",
    "print(linreg.score(X_train[included], y_train))\n",
    "print(linreg1.score(X2_train[included2], y_train))\n",
    "print(linreg_d.score(XD_train[included_d], y_train))\n",
    "print(linreg_dl.score(XDL_train[included_dl], y_train))\n",
    "print('-------')\n",
    "#Get score from test data\n",
    "print('Test Data Scores')\n",
    "print(linreg.score(X_test[included], y_test))\n",
    "print(linreg1.score(X2_test[included2], y_test))\n",
    "print(linreg_d.score(XD_test[included_d], y_test))\n",
    "print(linreg_dl.score(XDL_test[included_dl], y_test))\n",
    "print('-------')\n",
    "\n",
    "yDL_hat_test = linreg_dl.predict(XDL_test[included_dl])\n",
    "yDL_hat_train = linreg_dl.predict(XDL_train[included_dl])\n",
    "\n",
    "linreg_dl_rmse = np.sqrt(mean_squared_error(y_test, yDL_hat_test))\n",
    "linreg_dl_rmse_train = np.sqrt(mean_squared_error(y_train, yDL_hat_train))\n",
    "\n",
    "yD_hat_train = linreg_d.predict(XD_train[included_d])\n",
    "linreg_d_rmse_train = np.sqrt(mean_squared_error(y_train, yD_hat_train))\n",
    "\n",
    "#RMSE for all models train\n",
    "print('Train RMSE-------')\n",
    "print('First model train rmse:', round(linereg_rmse_train,0))\n",
    "print('Second model train rmse:', round(linereg2_rmse_train, 0))\n",
    "print('Model with dates train rmse:', round(linreg_d_rmse_train, 0))\n",
    "print('Model with dates & train zone rmse:', round(linreg_dl_rmse_train, 0))\n",
    "\n",
    "#RMSE for all models test\n",
    "print('Test RMSE-------')\n",
    "print('First model rmse:', round(linereg_rmse,0))\n",
    "print('Second Model rmse:', round(linereg2_rmse, 0))\n",
    "print('Model with dates rmse:', round(linreg_d_rmse,0))\n",
    "print('Model with dates & zone rmse:', round(linreg_dl_rmse,0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that adding lat-long numerical features actually degrades the model, by about 0.001 in the scores, and 500 dollars in the RMSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save final features for each model - to be used when predicting my house (need to select \n",
    "# appropriate columns)\n",
    "pickle.dump(included , open( \"included.p\", \"wb\" ) )\n",
    "pickle.dump( included2, open( \"included2.p\", \"wb\" ) )\n",
    "pickle.dump( included_d , open( \"included2_dates.p\", \"wb\" ) )\n",
    "pickle.dump( included_dl, open( \"included2_dates_latlong.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save models to be used in predicting my house (prediction notebook)\n",
    "pickle.dump( linreg, open( \"model_transform1.p\", \"wb\" ) )\n",
    "pickle.dump( linreg1, open( \"model_transform2.p\", \"wb\" ) )\n",
    "pickle.dump( linreg_d, open( \"model_transform2_dates.p\", \"wb\" ) )\n",
    "pickle.dump( linreg_dl, open( \"model_transform2_dates_latlong.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Investigate coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the top features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "linreg_best_coef = LinearRegression()\n",
    "selector = RFE(linreg_best_coef, n_features_to_select = 6)\n",
    "selector = selector.fit(XD_train[included_d], y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a total of 60 features included in the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(included_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_list = list(XD_train[included_d].columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['zip_98004', 'waterfront', 'zip_98039', 'zip_98112', 'zip_98040', 'zip_98102']"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_features = [column_list[i] for i, x in enumerate(selector.support_ ) if x]\n",
    "best_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow! Location, location, location. Obviously, waterfront property is a huge factor on price. And the rest are all zipcodes. \n",
    "98039 is where Bill gates lives. 98004 is Bellevue, also a highly desirable location, and almost not bad houses. 98112 also a desirable location in Seattle - where old big (and nice) houses are. 98040 - Mercer Island a desirable location filled with nature. 98102 also desirable given how much waterfront property there is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 852887.61535831 1033744.83817171 1706286.5239937   588664.04488533\n",
      "  666437.8776722   401045.84789684]\n",
      "498015.8015876963\n"
     ]
    }
   ],
   "source": [
    "estimators = selector.estimator_\n",
    "print(estimators.coef_)\n",
    "print(estimators.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the estimators. Waterfront propery add about 1 million dollars to the price, which seems quite appropriate. 1.7 million for the Bill Gates zip code, and under a million for Bellevue (98004) and for 98112 is closer to 600,000."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm surprised that number of bedrooms is not higher on the list, since it would be indicative of size features included in the list are 'sqft_living15', 'sqft_lot' - which are more about the neighboring house size or lots. (I guess regardless of the size of YOUR house it's also about the size of neighboring houses). But then again - often luxury houses add more rooms generally - such as a library, a veranda, indoor/outdoor room, large living rooms - so it may not always have to do with size. Similarly, houses further away from Seattle may have large lots and house size but are far away and people with money don't have jobs near there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector.ranking_[column_list.index('bedrooms')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save selector for future analysis.\n",
    "pickle.dump( selector, open( \"selector.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I wanted to see what a model trained with only these top 6 features would look like. It does quite badly, with a score of 0.26 or 0.25 on train data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2629280036138423"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linreg_dl = LinearRegression().fit(XD_train[best_features] , y_train)\n",
    "linreg_dl.score(XD_test[best_features] , y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25719391741946684"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linreg_dl.score(XD_train[best_features] , y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I kept iterating on the number of features and below I train successively on more features to see if there's a better model with fewer features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scores_at_included(num_features):\n",
    "    linreg_best_coef = LinearRegression()\n",
    "    selector = RFE(linreg_best_coef, n_features_to_select = num_features)\n",
    "    selector = selector.fit(XD_train[included_d], y_train)\n",
    "    \n",
    "    column_list = list(XD_train[included_d].columns)\n",
    "    best_features = [column_list[i] for i, x in enumerate(selector.support_ ) if x]\n",
    "    print('Best Features at using ' + str(num_features) + ' features')\n",
    "    #print(best_features)\n",
    "    \n",
    "    model = LinearRegression().fit(XD_train[best_features] , y_train)\n",
    "    score = model.score(XD_test[best_features] , y_test)\n",
    "    print(score)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Features at using 1 features\n",
      "0.044845656411425794\n",
      "Best Features at using 4 features\n",
      "0.21599767744175657\n",
      "Best Features at using 7 features\n",
      "0.26589980308193495\n",
      "Best Features at using 10 features\n",
      "0.30012929026395807\n",
      "Best Features at using 13 features\n",
      "0.322670350003041\n",
      "Best Features at using 16 features\n",
      "0.6147427228458564\n",
      "Best Features at using 19 features\n",
      "0.6208375917636331\n",
      "Best Features at using 22 features\n",
      "0.630376003004195\n",
      "Best Features at using 25 features\n",
      "0.6393645206802541\n",
      "Best Features at using 28 features\n",
      "0.6449692869703344\n",
      "Best Features at using 31 features\n",
      "0.6518598357289389\n",
      "Best Features at using 34 features\n",
      "0.6558525254297967\n",
      "Best Features at using 37 features\n",
      "0.6570176130096793\n",
      "Best Features at using 40 features\n",
      "0.6867673060790589\n",
      "Best Features at using 43 features\n",
      "0.6879917086550102\n",
      "Best Features at using 46 features\n",
      "0.6892067065338693\n",
      "Best Features at using 49 features\n",
      "0.6893926413682201\n",
      "Best Features at using 52 features\n",
      "0.7062463578623104\n",
      "Best Features at using 55 features\n",
      "0.7078180415842419\n",
      "Best Features at using 58 features\n",
      "0.7109765386011284\n",
      "Best Features at using 61 features\n",
      "0.7173378745287473\n"
     ]
    }
   ],
   "source": [
    "num_features_list = []\n",
    "scores = []\n",
    "for i in range(1, len(included_d) + 4, 3):\n",
    "    num_features_list.append(i)   \n",
    "    scores.append(scores_at_included(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#create graph of above\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(num_features_list, scores)\n",
    "plt.title(\"Scores of model when including top N features\")\n",
    "plt.xlabel('Number of features')\n",
    "plt.ylabel('Score')\n",
    "plt.show;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a sharp increase from 13 to 16 features. So if you care about including the fewest features 16 features with the highest amount of accuracy, then select 16 features. While if you care about the best model, then including everything that was selected from the stepwise function is the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:learn-env] *",
   "language": "python",
   "name": "conda-env-learn-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
